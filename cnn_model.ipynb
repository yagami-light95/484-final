{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generate_Captcha import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.input_x = tf.placeholder(\n",
    "            tf.float32, [None, Config.width * Config.height], name='input_x')\n",
    "        self.input_y = tf.placeholder(\n",
    "            tf.float32, [None, Config.char_num * len(Config.characters)], name='input_y')\n",
    "        self.keep_prob = tf.placeholder(\"float\")\n",
    "        self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "        self.CNN_model()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    @staticmethod\n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "    @staticmethod\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "    def CNN_model(self):\n",
    "        x_image = tf.reshape(self.input_x,\n",
    "                             [-1, Config.height, Config.width, 1], name='x_image')\n",
    "        # batch normalization\n",
    "        x_norm = tf.layers.batch_normalization(x_image,\n",
    "                                               training=self.training ,momentum=0.9)\n",
    "\n",
    "        # Convolutional layer 1:\n",
    "        w_cv1 = self.weight_variable([5, 5, 1, 32])\n",
    "        b_cv1 = self.bias_variable([32])\n",
    "        h_cv1 = tf.nn.relu(self.conv2d(x_norm, w_cv1) + b_cv1)\n",
    "        h_mp1 = self.max_pool_2x2(h_cv1)\n",
    "\n",
    "        # Convolutional layer 2：\n",
    "        w_cv2 = self.weight_variable([5, 5, 32, 64])\n",
    "        b_cv2 = self.bias_variable([64])\n",
    "        h_cv2 = tf.nn.relu(self.conv2d(h_mp1, w_cv2) + b_cv2)\n",
    "        h_mp2 = self.max_pool_2x2(h_cv2)\n",
    "\n",
    "        # Convolutional layer 3：\n",
    "        w_cv3 = self.weight_variable([5, 5, 64, 64])\n",
    "        b_cv3 = self.bias_variable([64])\n",
    "        h_cv3 = tf.nn.relu(self.conv2d(h_mp2, w_cv3) + b_cv3)\n",
    "        h_mp3 = self.max_pool_2x2(h_cv3)\n",
    "\n",
    "        # Fully connected layer\n",
    "        W_fc1 = self.weight_variable([20 * 8 * 64, 128])\n",
    "        b_fc1 = self.bias_variable([128])\n",
    "        h_mp3_flat = tf.reshape(h_mp3, [-1, 20 * 8 * 64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_mp3_flat, W_fc1) + b_fc1)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, self.keep_prob)\n",
    "\n",
    "        # Output layer\n",
    "        W_fc2 = self.weight_variable([128, Config.char_num * len(Config.characters)])\n",
    "        b_fc2 = self.bias_variable([Config.char_num * len(Config.characters)])\n",
    "        output = tf.add(tf.matmul(h_fc1_drop, W_fc2), b_fc2)\n",
    "\n",
    "        self.loss = (tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(labels=self.input_y, logits=output)))\n",
    "        predict = tf.reshape(output, [-1, Config.char_num,\n",
    "                                      len(Config.characters)], name='predict')\n",
    "        labels = tf.reshape(self.input_y, [-1, Config.char_num,\n",
    "                                           len(Config.characters)], name='labels')\n",
    "\n",
    "        self.predict_max_idx = tf.argmax(predict, axis=2, name='predict_max_idx')\n",
    "        labels_max_idx = tf.argmax(labels, axis=2, name='labels_max_idx')\n",
    "        predict_correct_vec = tf.equal(self.predict_max_idx, labels_max_idx)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_step = tf.train.AdamOptimizer(\n",
    "                Config.alpha).minimize(self.loss)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(predict_correct_vec, tf.float32))\n",
    "\n",
    "        # tensorboard\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "        tf.summary.scalar(\"accuracy\", self.accuracy)\n",
    "        self.merged_summary = tf.summary.merge_all()\n",
    "        self.writer = tf.summary.FileWriter(Config.tensorboard_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
