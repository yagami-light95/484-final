{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_model import *\n",
    "from Generate_Captcha import *\n",
    "import os\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run:\n",
    "\n",
    "    def __init__(self):\n",
    "        read = ReadData()\n",
    "        self.test_x, self.test_y, self.test_num = read.load_data(folder=Config.test_folder)\n",
    "        self.train_x, self.train_y, self.train_num = read.load_data(folder=Config.train_folder)\n",
    "        self.val_x, self.val_y, self.val_num = read.load_data(folder=Config.validation_folder)\n",
    "\n",
    "        print 'Images for train ：%d, for validation : %d, for test : %d' \\\n",
    "              % (self.train_num, self.val_num, self.test_num)\n",
    "\n",
    "        self.run_model()\n",
    "\n",
    "    @staticmethod\n",
    "    def next_batch(x, y, length):\n",
    "        if length % Config.batch_size == 0:\n",
    "            times = int(length / Config.batch_size)\n",
    "        else:\n",
    "            times = int(length / Config.batch_size) + 1\n",
    "\n",
    "        start_id = 0\n",
    "        for _ in range(times):\n",
    "            end_id = min(start_id + Config.batch_size, length)\n",
    "            batch_data = x[start_id:end_id]\n",
    "            batch_label = y[start_id:end_id]\n",
    "            start_id = end_id\n",
    "            yield batch_data, batch_label\n",
    "\n",
    "    @staticmethod\n",
    "    def feed_data(x, y, keep_prob, is_training=True):\n",
    "        feed_dict = {model.input_x: x,\n",
    "                     model.input_y: y,\n",
    "                     model.keep_prob: keep_prob,\n",
    "                     model.training: is_training}\n",
    "        return feed_dict\n",
    "\n",
    "    def evaluate(self, sess, val_x, val_y, val_size):\n",
    "        total_loss = 0.\n",
    "        total_acc = 0.\n",
    "\n",
    "        for x_, y_ in self.next_batch(val_x, val_y, val_size):\n",
    "            length = len(y_)\n",
    "            feed_dict = self.feed_data(x_, y_, 1.0, False)\n",
    "            val_acc, val_loss = sess.run([model.accuracy, model.loss], feed_dict=feed_dict)\n",
    "            total_acc += val_acc * length\n",
    "            total_loss += val_loss * length\n",
    "        return total_acc / val_size, total_loss / val_size\n",
    "\n",
    "    def run_model(self):\n",
    "\n",
    "        saver = tf.train.Saver(max_to_keep=1)\n",
    "        if not os.path.exists(Config.saver_folder):\n",
    "            os.mkdir(Config.saver_folder)\n",
    "        save_path = os.path.join(Config.saver_folder, 'best_validation')\n",
    "\n",
    "        total_batch = 0\n",
    "        best_acc = 0\n",
    "        last_improved_step = 0\n",
    "        require_steps = 1000\n",
    "        flag = False\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(Config.Epoch):\n",
    "            print 'Epoch : %d' % (epoch + 1)\n",
    "            for x, y in self.next_batch(self.train_x, self.train_y, self.train_num):\n",
    "                feed_dict = self.feed_data(x, y, Config.keep_prob, True)\n",
    "                sess.run(model.train_step, feed_dict=feed_dict)\n",
    "\n",
    "                if total_batch % Config.print_per_batch == 0:\n",
    "                    # Output the accuracy and loss values on the validation and training sets\n",
    "                    feed_dict[model.keep_prob] = 1.0\n",
    "                    feed_dict[model.training] = False\n",
    "                    train_accuracy, train_loss = sess.run([model.accuracy, model.loss],\n",
    "                                                          feed_dict=feed_dict)\n",
    "                    val_acc, val_loss = self.evaluate(sess, self.val_x, self.val_y, self.val_num)\n",
    "\n",
    "                    if val_acc > best_acc:\n",
    "                        # record the best result\n",
    "                        best_acc = val_acc\n",
    "                        last_improved_step = total_batch\n",
    "                        # store the model\n",
    "                        saver.save(sess=sess, save_path=save_path)\n",
    "                        improved = '*'\n",
    "                    else:\n",
    "                        improved = ''\n",
    "\n",
    "                    msg = 'Step {:5}, train_acc:{:8.2%}, train_loss:{:6.2f},' \\\n",
    "                          ' val_acc:{:8.2%}, val_loss:{:6.2f}, improved:{:3}'\n",
    "                    print msg.format(total_batch, train_accuracy, train_loss, val_acc, val_loss, improved)\n",
    "\n",
    "                if total_batch % Config.save_per_batch == 0:\n",
    "                    # write in tensorboard\n",
    "                    feed_dict[model.keep_prob] = 1.0\n",
    "                    feed_dict[model.training] = False\n",
    "                    s = sess.run(model.merged_summary, feed_dict=feed_dict)\n",
    "                    model.writer.add_summary(s, total_batch)\n",
    "\n",
    "                if total_batch - last_improved_step > require_steps:\n",
    "                    flag = True\n",
    "                    break\n",
    "\n",
    "                total_batch += 1\n",
    "            if flag:\n",
    "                print 'No improvement for over %d steps, auto-stopping....' % require_steps\n",
    "                break\n",
    "        end_time = datetime.now()\n",
    "        time_diff = (end_time - start_time).seconds\n",
    "        print 'Time Usage : {:.2f} hours'.format(time_diff / 3600.0)\n",
    "        # print the accuracy on the test set\n",
    "        test_acc, test_loss = self.evaluate(sess, self.test_x, self.test_y, self.test_num)\n",
    "\n",
    "        print \"Test accuracy:{:8.2%}, loss:{:6.2f}\".format(test_acc, test_loss)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From cnn_model.py:46: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /Users/lightyagami/opt/anaconda3/envs/tff/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From cnn_model.py:71: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Images for train ：10000, for validation : 500, for test : 500\n",
      "Epoch : 1\n",
      "Step     0, train_acc:  12.11%, train_loss:  1.97, val_acc:  10.20%, val_loss:  2.01, improved:*  \n",
      "Step    20, train_acc:   7.81%, train_loss:  0.48, val_acc:   9.70%, val_loss:  0.48, improved:   \n",
      "Step    40, train_acc:  10.94%, train_loss:  0.38, val_acc:   9.20%, val_loss:  0.39, improved:   \n",
      "Step    60, train_acc:  12.11%, train_loss:  0.35, val_acc:   8.70%, val_loss:  0.36, improved:   \n",
      "Step    80, train_acc:  12.11%, train_loss:  0.34, val_acc:   9.10%, val_loss:  0.34, improved:   \n",
      "Step   100, train_acc:  11.72%, train_loss:  0.33, val_acc:   9.45%, val_loss:  0.33, improved:   \n",
      "Step   120, train_acc:   9.38%, train_loss:  0.33, val_acc:   8.55%, val_loss:  0.33, improved:   \n",
      "Step   140, train_acc:  11.33%, train_loss:  0.33, val_acc:   8.80%, val_loss:  0.33, improved:   \n",
      "Epoch : 2\n",
      "Step   160, train_acc:  12.11%, train_loss:  0.33, val_acc:   9.30%, val_loss:  0.33, improved:   \n",
      "Step   180, train_acc:   8.20%, train_loss:  0.33, val_acc:   8.90%, val_loss:  0.33, improved:   \n",
      "Step   200, train_acc:  10.55%, train_loss:  0.33, val_acc:   9.30%, val_loss:  0.33, improved:   \n",
      "Step   220, train_acc:  14.45%, train_loss:  0.33, val_acc:   8.85%, val_loss:  0.33, improved:   \n",
      "Step   240, train_acc:  13.28%, train_loss:  0.33, val_acc:   9.95%, val_loss:  0.33, improved:   \n",
      "Step   260, train_acc:  10.55%, train_loss:  0.33, val_acc:  10.30%, val_loss:  0.33, improved:*  \n",
      "Step   280, train_acc:  14.06%, train_loss:  0.33, val_acc:  10.65%, val_loss:  0.33, improved:*  \n",
      "Step   300, train_acc:  12.89%, train_loss:  0.33, val_acc:  11.40%, val_loss:  0.33, improved:*  \n",
      "Epoch : 3\n",
      "Step   320, train_acc:  11.72%, train_loss:  0.33, val_acc:  10.60%, val_loss:  0.33, improved:   \n",
      "Step   340, train_acc:  10.94%, train_loss:  0.33, val_acc:  11.30%, val_loss:  0.33, improved:   \n",
      "Step   360, train_acc:  12.89%, train_loss:  0.33, val_acc:  10.95%, val_loss:  0.33, improved:   \n",
      "Step   380, train_acc:  13.67%, train_loss:  0.32, val_acc:  11.50%, val_loss:  0.33, improved:*  \n",
      "Step   400, train_acc:  10.16%, train_loss:  0.32, val_acc:  10.85%, val_loss:  0.33, improved:   \n",
      "Step   420, train_acc:  14.06%, train_loss:  0.33, val_acc:  11.90%, val_loss:  0.33, improved:*  \n",
      "Step   440, train_acc:  15.23%, train_loss:  0.33, val_acc:  11.50%, val_loss:  0.33, improved:   \n",
      "Step   460, train_acc:  10.16%, train_loss:  0.33, val_acc:  13.10%, val_loss:  0.32, improved:*  \n",
      "Epoch : 4\n",
      "Step   480, train_acc:  11.33%, train_loss:  0.32, val_acc:  11.90%, val_loss:  0.33, improved:   \n",
      "Step   500, train_acc:  14.84%, train_loss:  0.33, val_acc:  11.65%, val_loss:  0.33, improved:   \n",
      "Step   520, train_acc:  14.45%, train_loss:  0.32, val_acc:  13.65%, val_loss:  0.32, improved:*  \n",
      "Step   540, train_acc:  14.06%, train_loss:  0.32, val_acc:  12.95%, val_loss:  0.32, improved:   \n",
      "Step   560, train_acc:  15.62%, train_loss:  0.32, val_acc:  15.90%, val_loss:  0.32, improved:*  \n",
      "Step   580, train_acc:  16.41%, train_loss:  0.32, val_acc:  15.50%, val_loss:  0.32, improved:   \n",
      "Step   600, train_acc:  17.19%, train_loss:  0.32, val_acc:  16.80%, val_loss:  0.32, improved:*  \n",
      "Step   620, train_acc:  16.80%, train_loss:  0.32, val_acc:  19.15%, val_loss:  0.32, improved:*  \n",
      "Epoch : 5\n",
      "Step   640, train_acc:  22.66%, train_loss:  0.32, val_acc:  19.65%, val_loss:  0.32, improved:*  \n",
      "Step   660, train_acc:  24.22%, train_loss:  0.31, val_acc:  22.30%, val_loss:  0.32, improved:*  \n",
      "Step   680, train_acc:  24.22%, train_loss:  0.31, val_acc:  22.95%, val_loss:  0.31, improved:*  \n",
      "Step   700, train_acc:  28.91%, train_loss:  0.30, val_acc:  25.75%, val_loss:  0.31, improved:*  \n",
      "Step   720, train_acc:  27.73%, train_loss:  0.30, val_acc:  27.25%, val_loss:  0.30, improved:*  \n",
      "Step   740, train_acc:  35.16%, train_loss:  0.29, val_acc:  29.40%, val_loss:  0.30, improved:*  \n",
      "Step   760, train_acc:  33.59%, train_loss:  0.29, val_acc:  32.10%, val_loss:  0.29, improved:*  \n",
      "Step   780, train_acc:  37.89%, train_loss:  0.29, val_acc:  35.65%, val_loss:  0.29, improved:*  \n",
      "Epoch : 6\n",
      "Step   800, train_acc:  35.16%, train_loss:  0.29, val_acc:  35.50%, val_loss:  0.29, improved:   \n",
      "Step   820, train_acc:  42.58%, train_loss:  0.27, val_acc:  38.10%, val_loss:  0.28, improved:*  \n",
      "Step   840, train_acc:  41.02%, train_loss:  0.26, val_acc:  39.55%, val_loss:  0.27, improved:*  \n",
      "Step   860, train_acc:  47.66%, train_loss:  0.26, val_acc:  41.00%, val_loss:  0.27, improved:*  \n",
      "Step   880, train_acc:  44.92%, train_loss:  0.26, val_acc:  43.45%, val_loss:  0.26, improved:*  \n",
      "Step   900, train_acc:  45.31%, train_loss:  0.26, val_acc:  44.95%, val_loss:  0.26, improved:*  \n",
      "Step   920, train_acc:  52.34%, train_loss:  0.25, val_acc:  47.40%, val_loss:  0.25, improved:*  \n",
      "Step   940, train_acc:  51.17%, train_loss:  0.24, val_acc:  47.15%, val_loss:  0.25, improved:   \n",
      "Epoch : 7\n",
      "Step   960, train_acc:  50.00%, train_loss:  0.24, val_acc:  49.75%, val_loss:  0.25, improved:*  \n",
      "Step   980, train_acc:  50.39%, train_loss:  0.24, val_acc:  49.90%, val_loss:  0.24, improved:*  \n",
      "Step  1000, train_acc:  59.77%, train_loss:  0.22, val_acc:  52.85%, val_loss:  0.24, improved:*  \n",
      "Step  1020, train_acc:  53.52%, train_loss:  0.23, val_acc:  52.05%, val_loss:  0.23, improved:   \n",
      "Step  1040, train_acc:  55.47%, train_loss:  0.23, val_acc:  55.55%, val_loss:  0.23, improved:*  \n",
      "Step  1060, train_acc:  57.03%, train_loss:  0.23, val_acc:  55.30%, val_loss:  0.23, improved:   \n",
      "Step  1080, train_acc:  60.94%, train_loss:  0.22, val_acc:  56.50%, val_loss:  0.23, improved:*  \n",
      "Epoch : 8\n",
      "Step  1100, train_acc:  56.25%, train_loss:  0.22, val_acc:  56.75%, val_loss:  0.22, improved:*  \n",
      "Step  1120, train_acc:  63.67%, train_loss:  0.22, val_acc:  58.20%, val_loss:  0.22, improved:*  \n",
      "Step  1140, train_acc:  66.41%, train_loss:  0.21, val_acc:  60.05%, val_loss:  0.22, improved:*  \n",
      "Step  1160, train_acc:  62.11%, train_loss:  0.21, val_acc:  60.10%, val_loss:  0.22, improved:*  \n",
      "Step  1180, train_acc:  61.72%, train_loss:  0.22, val_acc:  61.95%, val_loss:  0.22, improved:*  \n",
      "Step  1200, train_acc:  57.03%, train_loss:  0.21, val_acc:  63.25%, val_loss:  0.21, improved:*  \n",
      "Step  1220, train_acc:  64.06%, train_loss:  0.21, val_acc:  62.05%, val_loss:  0.21, improved:   \n",
      "Step  1240, train_acc:  64.06%, train_loss:  0.21, val_acc:  64.40%, val_loss:  0.21, improved:*  \n",
      "Epoch : 9\n",
      "Step  1260, train_acc:  63.28%, train_loss:  0.21, val_acc:  62.65%, val_loss:  0.21, improved:   \n",
      "Step  1280, train_acc:  57.42%, train_loss:  0.21, val_acc:  65.15%, val_loss:  0.20, improved:*  \n",
      "Step  1300, train_acc:  66.80%, train_loss:  0.20, val_acc:  65.40%, val_loss:  0.20, improved:*  \n",
      "Step  1320, train_acc:  66.80%, train_loss:  0.20, val_acc:  66.15%, val_loss:  0.20, improved:*  \n",
      "Step  1340, train_acc:  68.75%, train_loss:  0.19, val_acc:  66.10%, val_loss:  0.20, improved:   \n",
      "Step  1360, train_acc:  69.92%, train_loss:  0.19, val_acc:  67.65%, val_loss:  0.20, improved:*  \n",
      "Step  1380, train_acc:  65.23%, train_loss:  0.20, val_acc:  66.95%, val_loss:  0.20, improved:   \n",
      "Step  1400, train_acc:  69.53%, train_loss:  0.19, val_acc:  68.40%, val_loss:  0.19, improved:*  \n",
      "Epoch : 10\n",
      "Step  1420, train_acc:  70.70%, train_loss:  0.19, val_acc:  68.25%, val_loss:  0.19, improved:   \n",
      "Step  1440, train_acc:  74.22%, train_loss:  0.18, val_acc:  68.95%, val_loss:  0.19, improved:*  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1460, train_acc:  75.00%, train_loss:  0.18, val_acc:  69.40%, val_loss:  0.19, improved:*  \n",
      "Step  1480, train_acc:  76.56%, train_loss:  0.17, val_acc:  69.40%, val_loss:  0.19, improved:*  \n",
      "Step  1500, train_acc:  73.83%, train_loss:  0.18, val_acc:  69.85%, val_loss:  0.18, improved:*  \n",
      "Step  1520, train_acc:  75.39%, train_loss:  0.18, val_acc:  70.30%, val_loss:  0.19, improved:*  \n",
      "Step  1540, train_acc:  74.22%, train_loss:  0.18, val_acc:  69.40%, val_loss:  0.18, improved:   \n",
      "Step  1560, train_acc:  66.41%, train_loss:  0.18, val_acc:  71.75%, val_loss:  0.18, improved:*  \n",
      "Epoch : 11\n",
      "Step  1580, train_acc:  73.05%, train_loss:  0.18, val_acc:  71.10%, val_loss:  0.18, improved:   \n",
      "Step  1600, train_acc:  69.14%, train_loss:  0.18, val_acc:  70.45%, val_loss:  0.18, improved:   \n",
      "Step  1620, train_acc:  77.73%, train_loss:  0.17, val_acc:  71.50%, val_loss:  0.18, improved:   \n",
      "Step  1640, train_acc:  76.95%, train_loss:  0.17, val_acc:  70.70%, val_loss:  0.18, improved:   \n",
      "Step  1660, train_acc:  70.31%, train_loss:  0.17, val_acc:  71.90%, val_loss:  0.18, improved:*  \n",
      "Step  1680, train_acc:  68.75%, train_loss:  0.17, val_acc:  72.20%, val_loss:  0.17, improved:*  \n",
      "Step  1700, train_acc:  65.23%, train_loss:  0.19, val_acc:  72.50%, val_loss:  0.17, improved:*  \n",
      "Step  1720, train_acc:  76.56%, train_loss:  0.16, val_acc:  73.05%, val_loss:  0.17, improved:*  \n",
      "Epoch : 12\n",
      "Step  1740, train_acc:  78.12%, train_loss:  0.15, val_acc:  72.85%, val_loss:  0.17, improved:   \n",
      "Step  1760, train_acc:  73.44%, train_loss:  0.17, val_acc:  73.20%, val_loss:  0.17, improved:*  \n",
      "Step  1780, train_acc:  75.39%, train_loss:  0.17, val_acc:  74.15%, val_loss:  0.17, improved:*  \n",
      "Step  1800, train_acc:  74.22%, train_loss:  0.18, val_acc:  73.25%, val_loss:  0.17, improved:   \n",
      "Step  1820, train_acc:  76.17%, train_loss:  0.15, val_acc:  74.05%, val_loss:  0.16, improved:   \n",
      "Step  1840, train_acc:  76.56%, train_loss:  0.16, val_acc:  75.45%, val_loss:  0.17, improved:*  \n",
      "Step  1860, train_acc:  78.12%, train_loss:  0.15, val_acc:  75.25%, val_loss:  0.16, improved:   \n",
      "Step  1880, train_acc:  77.34%, train_loss:  0.16, val_acc:  75.05%, val_loss:  0.16, improved:   \n",
      "Epoch : 13\n",
      "Step  1900, train_acc:  79.69%, train_loss:  0.15, val_acc:  75.10%, val_loss:  0.16, improved:   \n",
      "Step  1920, train_acc:  80.08%, train_loss:  0.14, val_acc:  74.95%, val_loss:  0.16, improved:   \n",
      "Step  1940, train_acc:  86.33%, train_loss:  0.14, val_acc:  75.65%, val_loss:  0.16, improved:*  \n",
      "Step  1960, train_acc:  78.12%, train_loss:  0.15, val_acc:  74.80%, val_loss:  0.16, improved:   \n",
      "Step  1980, train_acc:  78.91%, train_loss:  0.14, val_acc:  76.30%, val_loss:  0.15, improved:*  \n",
      "Step  2000, train_acc:  83.20%, train_loss:  0.14, val_acc:  77.85%, val_loss:  0.15, improved:*  \n",
      "Step  2020, train_acc:  81.25%, train_loss:  0.14, val_acc:  76.55%, val_loss:  0.15, improved:   \n",
      "Step  2040, train_acc:  84.38%, train_loss:  0.14, val_acc:  76.80%, val_loss:  0.15, improved:   \n",
      "Epoch : 14\n",
      "Step  2060, train_acc:  80.08%, train_loss:  0.14, val_acc:  78.15%, val_loss:  0.15, improved:*  \n",
      "Step  2080, train_acc:  85.94%, train_loss:  0.13, val_acc:  77.55%, val_loss:  0.15, improved:   \n",
      "Step  2100, train_acc:  82.81%, train_loss:  0.13, val_acc:  78.30%, val_loss:  0.15, improved:*  \n",
      "Step  2120, train_acc:  80.86%, train_loss:  0.14, val_acc:  77.30%, val_loss:  0.15, improved:   \n",
      "Step  2140, train_acc:  87.50%, train_loss:  0.12, val_acc:  79.15%, val_loss:  0.14, improved:*  \n",
      "Step  2160, train_acc:  80.47%, train_loss:  0.14, val_acc:  79.35%, val_loss:  0.14, improved:*  \n",
      "Step  2180, train_acc:  88.67%, train_loss:  0.12, val_acc:  79.45%, val_loss:  0.14, improved:*  \n",
      "Epoch : 15\n",
      "Step  2200, train_acc:  87.50%, train_loss:  0.12, val_acc:  79.30%, val_loss:  0.14, improved:   \n",
      "Step  2220, train_acc:  83.98%, train_loss:  0.13, val_acc:  81.00%, val_loss:  0.14, improved:*  \n",
      "Step  2240, train_acc:  88.67%, train_loss:  0.11, val_acc:  79.50%, val_loss:  0.14, improved:   \n",
      "Step  2260, train_acc:  79.30%, train_loss:  0.14, val_acc:  79.60%, val_loss:  0.14, improved:   \n",
      "Step  2280, train_acc:  87.50%, train_loss:  0.12, val_acc:  81.05%, val_loss:  0.14, improved:*  \n",
      "Step  2300, train_acc:  79.69%, train_loss:  0.14, val_acc:  80.85%, val_loss:  0.13, improved:   \n",
      "Step  2320, train_acc:  81.25%, train_loss:  0.13, val_acc:  81.50%, val_loss:  0.14, improved:*  \n",
      "Step  2340, train_acc:  88.28%, train_loss:  0.11, val_acc:  81.65%, val_loss:  0.13, improved:*  \n",
      "Epoch : 16\n",
      "Step  2360, train_acc:  86.33%, train_loss:  0.12, val_acc:  80.90%, val_loss:  0.13, improved:   \n",
      "Step  2380, train_acc:  87.50%, train_loss:  0.12, val_acc:  82.45%, val_loss:  0.13, improved:*  \n",
      "Step  2400, train_acc:  87.89%, train_loss:  0.11, val_acc:  82.90%, val_loss:  0.13, improved:*  \n",
      "Step  2420, train_acc:  90.62%, train_loss:  0.10, val_acc:  83.00%, val_loss:  0.13, improved:*  \n",
      "Step  2440, train_acc:  89.84%, train_loss:  0.10, val_acc:  83.05%, val_loss:  0.13, improved:*  \n",
      "Step  2460, train_acc:  88.67%, train_loss:  0.10, val_acc:  83.65%, val_loss:  0.12, improved:*  \n",
      "Step  2480, train_acc:  87.50%, train_loss:  0.11, val_acc:  83.20%, val_loss:  0.13, improved:   \n",
      "Step  2500, train_acc:  88.28%, train_loss:  0.11, val_acc:  83.45%, val_loss:  0.12, improved:   \n",
      "Epoch : 17\n",
      "Step  2520, train_acc:  89.45%, train_loss:  0.10, val_acc:  84.60%, val_loss:  0.12, improved:*  \n",
      "Step  2540, train_acc:  91.80%, train_loss:  0.10, val_acc:  83.45%, val_loss:  0.12, improved:   \n",
      "Step  2560, train_acc:  89.06%, train_loss:  0.10, val_acc:  84.35%, val_loss:  0.12, improved:   \n",
      "Step  2580, train_acc:  83.20%, train_loss:  0.11, val_acc:  83.10%, val_loss:  0.12, improved:   \n",
      "Step  2600, train_acc:  93.75%, train_loss:  0.08, val_acc:  84.00%, val_loss:  0.12, improved:   \n",
      "Step  2620, train_acc:  87.89%, train_loss:  0.10, val_acc:  84.50%, val_loss:  0.12, improved:   \n",
      "Step  2640, train_acc:  90.62%, train_loss:  0.09, val_acc:  84.50%, val_loss:  0.11, improved:   \n",
      "Step  2660, train_acc:  91.02%, train_loss:  0.10, val_acc:  85.25%, val_loss:  0.11, improved:*  \n",
      "Epoch : 18\n",
      "Step  2680, train_acc:  90.62%, train_loss:  0.10, val_acc:  85.15%, val_loss:  0.11, improved:   \n",
      "Step  2700, train_acc:  88.67%, train_loss:  0.09, val_acc:  85.05%, val_loss:  0.11, improved:   \n",
      "Step  2720, train_acc:  90.62%, train_loss:  0.09, val_acc:  85.85%, val_loss:  0.11, improved:*  \n",
      "Step  2740, train_acc:  92.58%, train_loss:  0.09, val_acc:  85.05%, val_loss:  0.11, improved:   \n",
      "Step  2760, train_acc:  87.50%, train_loss:  0.09, val_acc:  85.35%, val_loss:  0.11, improved:   \n",
      "Step  2780, train_acc:  91.41%, train_loss:  0.08, val_acc:  85.95%, val_loss:  0.11, improved:*  \n",
      "Step  2800, train_acc:  91.02%, train_loss:  0.09, val_acc:  86.35%, val_loss:  0.11, improved:*  \n",
      "Step  2820, train_acc:  92.97%, train_loss:  0.08, val_acc:  87.20%, val_loss:  0.10, improved:*  \n",
      "Epoch : 19\n",
      "Step  2840, train_acc:  91.41%, train_loss:  0.09, val_acc:  86.60%, val_loss:  0.10, improved:   \n",
      "Step  2860, train_acc:  94.92%, train_loss:  0.07, val_acc:  86.90%, val_loss:  0.10, improved:   \n",
      "Step  2880, train_acc:  94.53%, train_loss:  0.07, val_acc:  87.00%, val_loss:  0.10, improved:   \n",
      "Step  2900, train_acc:  91.80%, train_loss:  0.09, val_acc:  86.35%, val_loss:  0.10, improved:   \n",
      "Step  2920, train_acc:  90.23%, train_loss:  0.09, val_acc:  87.05%, val_loss:  0.10, improved:   \n",
      "Step  2940, train_acc:  93.75%, train_loss:  0.07, val_acc:  88.10%, val_loss:  0.10, improved:*  \n",
      "Step  2960, train_acc:  94.53%, train_loss:  0.07, val_acc:  88.30%, val_loss:  0.10, improved:*  \n",
      "Step  2980, train_acc:  93.75%, train_loss:  0.07, val_acc:  88.00%, val_loss:  0.09, improved:   \n",
      "Epoch : 20\n",
      "Step  3000, train_acc:  93.75%, train_loss:  0.07, val_acc:  88.50%, val_loss:  0.10, improved:*  \n",
      "Step  3020, train_acc:  92.58%, train_loss:  0.07, val_acc:  88.10%, val_loss:  0.09, improved:   \n",
      "Step  3040, train_acc:  93.36%, train_loss:  0.07, val_acc:  88.05%, val_loss:  0.10, improved:   \n",
      "Step  3060, train_acc:  93.36%, train_loss:  0.07, val_acc:  87.90%, val_loss:  0.10, improved:   \n",
      "Step  3080, train_acc:  92.97%, train_loss:  0.06, val_acc:  87.85%, val_loss:  0.10, improved:   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  3100, train_acc:  92.19%, train_loss:  0.07, val_acc:  88.05%, val_loss:  0.09, improved:   \n",
      "Step  3120, train_acc:  95.31%, train_loss:  0.06, val_acc:  89.15%, val_loss:  0.09, improved:*  \n",
      "Epoch : 21\n",
      "Step  3140, train_acc:  94.92%, train_loss:  0.06, val_acc:  89.05%, val_loss:  0.09, improved:   \n",
      "Step  3160, train_acc:  96.09%, train_loss:  0.06, val_acc:  89.55%, val_loss:  0.09, improved:*  \n",
      "Step  3180, train_acc:  95.31%, train_loss:  0.06, val_acc:  88.80%, val_loss:  0.09, improved:   \n",
      "Step  3200, train_acc:  95.31%, train_loss:  0.06, val_acc:  89.60%, val_loss:  0.09, improved:*  \n",
      "Step  3220, train_acc:  96.48%, train_loss:  0.05, val_acc:  89.55%, val_loss:  0.09, improved:   \n",
      "Step  3240, train_acc:  95.70%, train_loss:  0.05, val_acc:  89.35%, val_loss:  0.08, improved:   \n",
      "Step  3260, train_acc:  93.36%, train_loss:  0.06, val_acc:  90.20%, val_loss:  0.09, improved:*  \n",
      "Step  3280, train_acc:  95.31%, train_loss:  0.05, val_acc:  90.25%, val_loss:  0.08, improved:*  \n",
      "Epoch : 22\n",
      "Step  3300, train_acc:  91.02%, train_loss:  0.06, val_acc:  90.30%, val_loss:  0.08, improved:*  \n",
      "Step  3320, train_acc:  93.75%, train_loss:  0.06, val_acc:  90.50%, val_loss:  0.08, improved:*  \n",
      "Step  3340, train_acc:  92.97%, train_loss:  0.07, val_acc:  90.50%, val_loss:  0.08, improved:   \n",
      "Step  3360, train_acc:  92.58%, train_loss:  0.06, val_acc:  90.40%, val_loss:  0.08, improved:   \n",
      "Step  3380, train_acc:  96.09%, train_loss:  0.05, val_acc:  90.85%, val_loss:  0.08, improved:*  \n",
      "Step  3400, train_acc:  93.75%, train_loss:  0.06, val_acc:  90.85%, val_loss:  0.08, improved:   \n",
      "Step  3420, train_acc:  94.14%, train_loss:  0.06, val_acc:  90.75%, val_loss:  0.08, improved:   \n",
      "Step  3440, train_acc:  94.53%, train_loss:  0.05, val_acc:  91.70%, val_loss:  0.08, improved:*  \n",
      "Epoch : 23\n",
      "Step  3460, train_acc:  95.31%, train_loss:  0.05, val_acc:  91.70%, val_loss:  0.08, improved:   \n",
      "Step  3480, train_acc:  92.97%, train_loss:  0.06, val_acc:  89.35%, val_loss:  0.08, improved:   \n",
      "Step  3500, train_acc:  94.14%, train_loss:  0.05, val_acc:  90.60%, val_loss:  0.08, improved:   \n",
      "Step  3520, train_acc:  94.92%, train_loss:  0.06, val_acc:  91.30%, val_loss:  0.08, improved:   \n",
      "Step  3540, train_acc:  97.27%, train_loss:  0.05, val_acc:  91.20%, val_loss:  0.08, improved:   \n",
      "Step  3560, train_acc:  96.48%, train_loss:  0.04, val_acc:  91.00%, val_loss:  0.07, improved:   \n",
      "Step  3580, train_acc:  96.48%, train_loss:  0.05, val_acc:  91.15%, val_loss:  0.08, improved:   \n",
      "Step  3600, train_acc:  96.88%, train_loss:  0.04, val_acc:  91.20%, val_loss:  0.07, improved:   \n",
      "Epoch : 24\n",
      "Step  3620, train_acc:  96.48%, train_loss:  0.05, val_acc:  91.35%, val_loss:  0.07, improved:   \n",
      "Step  3640, train_acc:  96.88%, train_loss:  0.04, val_acc:  91.10%, val_loss:  0.08, improved:   \n",
      "Step  3660, train_acc:  97.66%, train_loss:  0.04, val_acc:  91.65%, val_loss:  0.07, improved:   \n",
      "Step  3680, train_acc:  95.70%, train_loss:  0.05, val_acc:  91.75%, val_loss:  0.07, improved:*  \n",
      "Step  3700, train_acc:  95.70%, train_loss:  0.05, val_acc:  91.95%, val_loss:  0.07, improved:*  \n",
      "Step  3720, train_acc:  96.88%, train_loss:  0.05, val_acc:  91.55%, val_loss:  0.07, improved:   \n",
      "Step  3740, train_acc:  96.88%, train_loss:  0.04, val_acc:  92.15%, val_loss:  0.07, improved:*  \n",
      "Step  3760, train_acc:  97.66%, train_loss:  0.04, val_acc:  92.60%, val_loss:  0.07, improved:*  \n",
      "Epoch : 25\n",
      "Step  3780, train_acc:  96.88%, train_loss:  0.04, val_acc:  92.75%, val_loss:  0.07, improved:*  \n",
      "Step  3800, train_acc:  96.48%, train_loss:  0.04, val_acc:  91.95%, val_loss:  0.07, improved:   \n",
      "Step  3820, train_acc:  95.31%, train_loss:  0.05, val_acc:  91.35%, val_loss:  0.07, improved:   \n",
      "Step  3840, train_acc:  96.48%, train_loss:  0.05, val_acc:  92.70%, val_loss:  0.07, improved:   \n",
      "Step  3860, train_acc:  97.66%, train_loss:  0.04, val_acc:  92.00%, val_loss:  0.07, improved:   \n",
      "Step  3880, train_acc:  96.88%, train_loss:  0.04, val_acc:  92.20%, val_loss:  0.07, improved:   \n",
      "Step  3900, train_acc:  97.27%, train_loss:  0.04, val_acc:  92.50%, val_loss:  0.07, improved:   \n",
      "Step  3920, train_acc:  96.48%, train_loss:  0.04, val_acc:  92.50%, val_loss:  0.07, improved:   \n",
      "Epoch : 26\n",
      "Step  3940, train_acc:  95.70%, train_loss:  0.04, val_acc:  92.90%, val_loss:  0.07, improved:*  \n",
      "Step  3960, train_acc:  97.66%, train_loss:  0.03, val_acc:  91.55%, val_loss:  0.07, improved:   \n",
      "Step  3980, train_acc:  98.44%, train_loss:  0.04, val_acc:  92.65%, val_loss:  0.07, improved:   \n",
      "Step  4000, train_acc:  98.05%, train_loss:  0.04, val_acc:  92.70%, val_loss:  0.07, improved:   \n",
      "Step  4020, train_acc:  98.05%, train_loss:  0.03, val_acc:  92.05%, val_loss:  0.07, improved:   \n",
      "Step  4040, train_acc:  98.44%, train_loss:  0.04, val_acc:  92.65%, val_loss:  0.07, improved:   \n",
      "Step  4060, train_acc:  97.27%, train_loss:  0.03, val_acc:  92.75%, val_loss:  0.07, improved:   \n",
      "Step  4080, train_acc:  97.66%, train_loss:  0.04, val_acc:  92.90%, val_loss:  0.07, improved:*  \n",
      "Epoch : 27\n",
      "Step  4100, train_acc:  98.05%, train_loss:  0.03, val_acc:  92.80%, val_loss:  0.06, improved:   \n",
      "Step  4120, train_acc:  98.05%, train_loss:  0.03, val_acc:  92.40%, val_loss:  0.07, improved:   \n",
      "Step  4140, train_acc:  98.05%, train_loss:  0.03, val_acc:  91.80%, val_loss:  0.07, improved:   \n",
      "Step  4160, train_acc:  99.22%, train_loss:  0.03, val_acc:  93.10%, val_loss:  0.07, improved:*  \n",
      "Step  4180, train_acc:  97.66%, train_loss:  0.03, val_acc:  92.20%, val_loss:  0.06, improved:   \n",
      "Step  4200, train_acc:  97.27%, train_loss:  0.03, val_acc:  93.60%, val_loss:  0.06, improved:*  \n",
      "Step  4220, train_acc:  98.44%, train_loss:  0.03, val_acc:  93.15%, val_loss:  0.06, improved:   \n",
      "Epoch : 28\n",
      "Step  4240, train_acc:  98.05%, train_loss:  0.03, val_acc:  93.35%, val_loss:  0.06, improved:   \n",
      "Step  4260, train_acc:  98.83%, train_loss:  0.03, val_acc:  92.95%, val_loss:  0.06, improved:   \n",
      "Step  4280, train_acc:  99.61%, train_loss:  0.03, val_acc:  93.15%, val_loss:  0.07, improved:   \n",
      "Step  4300, train_acc:  96.88%, train_loss:  0.04, val_acc:  92.80%, val_loss:  0.06, improved:   \n",
      "Step  4320, train_acc:  97.27%, train_loss:  0.03, val_acc:  93.40%, val_loss:  0.06, improved:   \n",
      "Step  4340, train_acc:  98.83%, train_loss:  0.03, val_acc:  93.40%, val_loss:  0.06, improved:   \n",
      "Step  4360, train_acc:  99.22%, train_loss:  0.03, val_acc:  93.65%, val_loss:  0.06, improved:*  \n",
      "Step  4380, train_acc:  97.66%, train_loss:  0.03, val_acc:  93.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 29\n",
      "Step  4400, train_acc:  96.48%, train_loss:  0.03, val_acc:  94.00%, val_loss:  0.06, improved:*  \n",
      "Step  4420, train_acc:  96.48%, train_loss:  0.04, val_acc:  93.95%, val_loss:  0.06, improved:   \n",
      "Step  4440, train_acc:  99.61%, train_loss:  0.03, val_acc:  93.45%, val_loss:  0.07, improved:   \n",
      "Step  4460, train_acc:  98.83%, train_loss:  0.02, val_acc:  93.60%, val_loss:  0.06, improved:   \n",
      "Step  4480, train_acc:  98.83%, train_loss:  0.03, val_acc:  94.10%, val_loss:  0.06, improved:*  \n",
      "Step  4500, train_acc:  98.83%, train_loss:  0.03, val_acc:  93.85%, val_loss:  0.06, improved:   \n",
      "Step  4520, train_acc:  98.05%, train_loss:  0.03, val_acc:  93.55%, val_loss:  0.06, improved:   \n",
      "Step  4540, train_acc:  98.44%, train_loss:  0.03, val_acc:  93.90%, val_loss:  0.06, improved:   \n",
      "Epoch : 30\n",
      "Step  4560, train_acc:  98.05%, train_loss:  0.03, val_acc:  94.00%, val_loss:  0.06, improved:   \n",
      "Step  4580, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.05%, val_loss:  0.06, improved:   \n",
      "Step  4600, train_acc:  99.22%, train_loss:  0.02, val_acc:  93.45%, val_loss:  0.06, improved:   \n",
      "Step  4620, train_acc:  97.66%, train_loss:  0.02, val_acc:  94.20%, val_loss:  0.06, improved:*  \n",
      "Step  4640, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.10%, val_loss:  0.06, improved:   \n",
      "Step  4660, train_acc:  98.44%, train_loss:  0.02, val_acc:  94.45%, val_loss:  0.06, improved:*  \n",
      "Step  4680, train_acc:  98.83%, train_loss:  0.03, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Step  4700, train_acc:  98.05%, train_loss:  0.03, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Epoch : 31\n",
      "Step  4720, train_acc:  96.88%, train_loss:  0.03, val_acc:  94.25%, val_loss:  0.06, improved:   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  4740, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.25%, val_loss:  0.06, improved:   \n",
      "Step  4760, train_acc:  97.27%, train_loss:  0.03, val_acc:  93.80%, val_loss:  0.06, improved:   \n",
      "Step  4780, train_acc:  98.44%, train_loss:  0.02, val_acc:  93.50%, val_loss:  0.06, improved:   \n",
      "Step  4800, train_acc:  98.44%, train_loss:  0.02, val_acc:  94.35%, val_loss:  0.06, improved:   \n",
      "Step  4820, train_acc:  99.22%, train_loss:  0.02, val_acc:  95.05%, val_loss:  0.06, improved:*  \n",
      "Step  4840, train_acc:  98.44%, train_loss:  0.03, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Step  4860, train_acc:  98.83%, train_loss:  0.02, val_acc:  93.70%, val_loss:  0.06, improved:   \n",
      "Epoch : 32\n",
      "Step  4880, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.25%, val_loss:  0.05, improved:   \n",
      "Step  4900, train_acc:  98.05%, train_loss:  0.02, val_acc:  94.25%, val_loss:  0.06, improved:   \n",
      "Step  4920, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Step  4940, train_acc:  98.05%, train_loss:  0.02, val_acc:  94.15%, val_loss:  0.06, improved:   \n",
      "Step  4960, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.35%, val_loss:  0.06, improved:   \n",
      "Step  4980, train_acc: 100.00%, train_loss:  0.02, val_acc:  95.00%, val_loss:  0.06, improved:   \n",
      "Step  5000, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Step  5020, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.55%, val_loss:  0.06, improved:   \n",
      "Epoch : 33\n",
      "Step  5040, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Step  5060, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:*  \n",
      "Step  5080, train_acc: 100.00%, train_loss:  0.02, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  5100, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Step  5120, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.35%, val_loss:  0.06, improved:   \n",
      "Step  5140, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.05%, val_loss:  0.05, improved:   \n",
      "Step  5160, train_acc:  99.61%, train_loss:  0.02, val_acc:  93.95%, val_loss:  0.06, improved:   \n",
      "Step  5180, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.40%, val_loss:  0.06, improved:   \n",
      "Epoch : 34\n",
      "Step  5200, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.05, improved:   \n",
      "Step  5220, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  5240, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.70%, val_loss:  0.05, improved:   \n",
      "Step  5260, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.80%, val_loss:  0.06, improved:   \n",
      "Step  5280, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  5300, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.60%, val_loss:  0.05, improved:   \n",
      "Step  5320, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 35\n",
      "Step  5340, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Step  5360, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.35%, val_loss:  0.05, improved:   \n",
      "Step  5380, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.55%, val_loss:  0.06, improved:   \n",
      "Step  5400, train_acc:  97.27%, train_loss:  0.03, val_acc:  94.80%, val_loss:  0.05, improved:   \n",
      "Step  5420, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.40%, val_loss:  0.06, improved:   \n",
      "Step  5440, train_acc:  99.22%, train_loss:  0.02, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  5460, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.75%, val_loss:  0.05, improved:   \n",
      "Step  5480, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.30%, val_loss:  0.05, improved:   \n",
      "Epoch : 36\n",
      "Step  5500, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.05%, val_loss:  0.06, improved:   \n",
      "Step  5520, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.60%, val_loss:  0.05, improved:   \n",
      "Step  5540, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.55%, val_loss:  0.06, improved:   \n",
      "Step  5560, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.05, improved:*  \n",
      "Step  5580, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.05, improved:   \n",
      "Step  5600, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Step  5620, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Step  5640, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.20%, val_loss:  0.06, improved:   \n",
      "Epoch : 37\n",
      "Step  5660, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.40%, val_loss:  0.06, improved:   \n",
      "Step  5680, train_acc:  99.61%, train_loss:  0.02, val_acc:  94.95%, val_loss:  0.05, improved:   \n",
      "Step  5700, train_acc:  98.83%, train_loss:  0.01, val_acc:  94.90%, val_loss:  0.06, improved:   \n",
      "Step  5720, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.05, improved:   \n",
      "Step  5740, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.05, improved:   \n",
      "Step  5760, train_acc:  98.83%, train_loss:  0.02, val_acc:  94.15%, val_loss:  0.06, improved:   \n",
      "Step  5780, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.90%, val_loss:  0.06, improved:   \n",
      "Step  5800, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.55%, val_loss:  0.06, improved:   \n",
      "Epoch : 38\n",
      "Step  5820, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.10%, val_loss:  0.06, improved:   \n",
      "Step  5840, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.05, improved:   \n",
      "Step  5860, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.90%, val_loss:  0.06, improved:   \n",
      "Step  5880, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.65%, val_loss:  0.06, improved:   \n",
      "Step  5900, train_acc:  98.83%, train_loss:  0.02, val_acc:  95.15%, val_loss:  0.05, improved:*  \n",
      "Step  5920, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.55%, val_loss:  0.06, improved:   \n",
      "Step  5940, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.30%, val_loss:  0.06, improved:   \n",
      "Step  5960, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.05%, val_loss:  0.06, improved:   \n",
      "Epoch : 39\n",
      "Step  5980, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.05, improved:   \n",
      "Step  6000, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Step  6020, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.70%, val_loss:  0.06, improved:   \n",
      "Step  6040, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  6060, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:*  \n",
      "Step  6080, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.80%, val_loss:  0.05, improved:   \n",
      "Step  6100, train_acc:  99.61%, train_loss:  0.01, val_acc:  93.90%, val_loss:  0.06, improved:   \n",
      "Step  6120, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Epoch : 40\n",
      "Step  6140, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.30%, val_loss:  0.05, improved:   \n",
      "Step  6160, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  6180, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Step  6200, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:*  \n",
      "Step  6220, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.05, improved:   \n",
      "Step  6240, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:   \n",
      "Step  6260, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.65%, val_loss:  0.06, improved:   \n",
      "Epoch : 41\n",
      "Step  6280, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  6300, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.05, improved:   \n",
      "Step  6320, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.40%, val_loss:  0.06, improved:   \n",
      "Step  6340, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  6360, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.05, improved:   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  6380, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.06, improved:   \n",
      "Step  6400, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:   \n",
      "Step  6420, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Epoch : 42\n",
      "Step  6440, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.06, improved:   \n",
      "Step  6460, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.05, improved:   \n",
      "Step  6480, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.05, improved:   \n",
      "Step  6500, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Step  6520, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Step  6540, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  6560, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.05, improved:   \n",
      "Step  6580, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.65%, val_loss:  0.06, improved:   \n",
      "Epoch : 43\n",
      "Step  6600, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.80%, val_loss:  0.06, improved:   \n",
      "Step  6620, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.90%, val_loss:  0.05, improved:   \n",
      "Step  6640, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.06, improved:   \n",
      "Step  6660, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.05, improved:   \n",
      "Step  6680, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.90%, val_loss:  0.05, improved:   \n",
      "Step  6700, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.05, improved:   \n",
      "Step  6720, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:*  \n",
      "Step  6740, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.06, improved:   \n",
      "Epoch : 44\n",
      "Step  6760, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.06, improved:   \n",
      "Step  6780, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.05, improved:   \n",
      "Step  6800, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  6820, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:   \n",
      "Step  6840, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Step  6860, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.05, improved:   \n",
      "Step  6880, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  6900, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.06, improved:   \n",
      "Epoch : 45\n",
      "Step  6920, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.80%, val_loss:  0.06, improved:   \n",
      "Step  6940, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.60%, val_loss:  0.06, improved:   \n",
      "Step  6960, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  6980, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.05, improved:   \n",
      "Step  7000, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.80%, val_loss:  0.05, improved:   \n",
      "Step  7020, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Step  7040, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Step  7060, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Epoch : 46\n",
      "Step  7080, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  7100, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:*  \n",
      "Step  7120, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.85%, val_loss:  0.05, improved:*  \n",
      "Step  7140, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.05, improved:   \n",
      "Step  7160, train_acc:  99.22%, train_loss:  0.01, val_acc:  94.75%, val_loss:  0.06, improved:   \n",
      "Step  7180, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.15%, val_loss:  0.06, improved:   \n",
      "Step  7200, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.35%, val_loss:  0.06, improved:   \n",
      "Step  7220, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 47\n",
      "Step  7240, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.05, improved:   \n",
      "Step  7260, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.05, improved:   \n",
      "Step  7280, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.25%, val_loss:  0.06, improved:   \n",
      "Step  7300, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.05, improved:   \n",
      "Step  7320, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Step  7340, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.45%, val_loss:  0.06, improved:   \n",
      "Step  7360, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:   \n",
      "Epoch : 48\n",
      "Step  7380, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.70%, val_loss:  0.06, improved:   \n",
      "Step  7400, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.30%, val_loss:  0.05, improved:   \n",
      "Step  7420, train_acc:  99.61%, train_loss:  0.01, val_acc:  94.70%, val_loss:  0.06, improved:   \n",
      "Step  7440, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  7460, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  7480, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  7500, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  7520, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 49\n",
      "Step  7540, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  7560, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.05, improved:   \n",
      "Step  7580, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  7600, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Step  7620, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.05%, val_loss:  0.06, improved:   \n",
      "Step  7640, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.06, improved:   \n",
      "Step  7660, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:   \n",
      "Step  7680, train_acc:  99.22%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.06, improved:   \n",
      "Epoch : 50\n",
      "Step  7700, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Step  7720, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.75%, val_loss:  0.05, improved:   \n",
      "Step  7740, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.05, improved:   \n",
      "Step  7760, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:   \n",
      "Step  7780, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.55%, val_loss:  0.05, improved:   \n",
      "Step  7800, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.55%, val_loss:  0.05, improved:   \n",
      "Step  7820, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.05, improved:   \n",
      "Step  7840, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.06, improved:   \n",
      "Epoch : 51\n",
      "Step  7860, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.45%, val_loss:  0.06, improved:   \n",
      "Step  7880, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.60%, val_loss:  0.05, improved:   \n",
      "Step  7900, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.95%, val_loss:  0.05, improved:*  \n",
      "Step  7920, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.06, improved:   \n",
      "Step  7940, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.06, improved:   \n",
      "Step  7960, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.70%, val_loss:  0.05, improved:   \n",
      "Step  7980, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.55%, val_loss:  0.05, improved:   \n",
      "Step  8000, train_acc:  99.61%, train_loss:  0.01, val_acc:  96.20%, val_loss:  0.05, improved:*  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 52\n",
      "Step  8020, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  8040, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.60%, val_loss:  0.06, improved:   \n",
      "Step  8060, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  8080, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.40%, val_loss:  0.06, improved:   \n",
      "Step  8100, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  8120, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.45%, val_loss:  0.05, improved:   \n",
      "Step  8140, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  8160, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 53\n",
      "Step  8180, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.65%, val_loss:  0.05, improved:   \n",
      "Step  8200, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.60%, val_loss:  0.05, improved:   \n",
      "Step  8220, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.60%, val_loss:  0.06, improved:   \n",
      "Step  8240, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.60%, val_loss:  0.05, improved:   \n",
      "Step  8260, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Step  8280, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.20%, val_loss:  0.05, improved:   \n",
      "Step  8300, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.35%, val_loss:  0.06, improved:   \n",
      "Step  8320, train_acc: 100.00%, train_loss:  0.00, val_acc:  94.85%, val_loss:  0.06, improved:   \n",
      "Epoch : 54\n",
      "Step  8340, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  8360, train_acc: 100.00%, train_loss:  0.00, val_acc:  94.90%, val_loss:  0.06, improved:   \n",
      "Step  8380, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.00%, val_loss:  0.06, improved:   \n",
      "Step  8400, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Step  8420, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  8440, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.06, improved:   \n",
      "Step  8460, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.90%, val_loss:  0.06, improved:   \n",
      "Epoch : 55\n",
      "Step  8480, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.60%, val_loss:  0.06, improved:   \n",
      "Step  8500, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.90%, val_loss:  0.06, improved:   \n",
      "Step  8520, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  8540, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.45%, val_loss:  0.06, improved:   \n",
      "Step  8560, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.45%, val_loss:  0.05, improved:   \n",
      "Step  8580, train_acc: 100.00%, train_loss:  0.01, val_acc:  96.05%, val_loss:  0.06, improved:   \n",
      "Step  8600, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.35%, val_loss:  0.06, improved:   \n",
      "Step  8620, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.50%, val_loss:  0.06, improved:   \n",
      "Epoch : 56\n",
      "Step  8640, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.40%, val_loss:  0.06, improved:   \n",
      "Step  8660, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  8680, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.10%, val_loss:  0.06, improved:   \n",
      "Step  8700, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.35%, val_loss:  0.06, improved:   \n",
      "Step  8720, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  8740, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.25%, val_loss:  0.06, improved:   \n",
      "Step  8760, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.60%, val_loss:  0.06, improved:   \n",
      "Step  8780, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.65%, val_loss:  0.06, improved:   \n",
      "Epoch : 57\n",
      "Step  8800, train_acc: 100.00%, train_loss:  0.01, val_acc:  94.95%, val_loss:  0.06, improved:   \n",
      "Step  8820, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.30%, val_loss:  0.06, improved:   \n",
      "Step  8840, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.60%, val_loss:  0.06, improved:   \n",
      "Step  8860, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.65%, val_loss:  0.05, improved:   \n",
      "Step  8880, train_acc: 100.00%, train_loss:  0.00, val_acc:  96.05%, val_loss:  0.06, improved:   \n",
      "Step  8900, train_acc:  99.61%, train_loss:  0.01, val_acc:  96.00%, val_loss:  0.05, improved:   \n",
      "Step  8920, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.80%, val_loss:  0.06, improved:   \n",
      "Step  8940, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Epoch : 58\n",
      "Step  8960, train_acc:  99.61%, train_loss:  0.01, val_acc:  95.45%, val_loss:  0.06, improved:   \n",
      "Step  8980, train_acc: 100.00%, train_loss:  0.00, val_acc:  95.55%, val_loss:  0.06, improved:   \n",
      "Step  9000, train_acc: 100.00%, train_loss:  0.01, val_acc:  95.70%, val_loss:  0.06, improved:   \n",
      "No improvement for over 1000 steps, auto-stopping....\n",
      "Time Usage : 8.18 hours\n",
      "Test accuracy:  94.10%, loss:  0.07\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = CNN()\n",
    "    Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
